# Wonk 聊天机器人方案评估

## 需求摘要
- 数据：10条左右问答对起步，后续可增长
- 语言：中英文双语
- 目标：本地离线可用，商用可行
- 优先级：先实现功能，再做UI

## 候选方案

### 方案 A：BM25 + 语义向量（推荐）
- 关键词检索（SQLite FTS5）+ 语义向量检索（FAISS + 多语言小模型）
- 置信度阈值+候选展示，确保回答可控

优点：
- 全流程可离线；迭代简单；对小规模FAQ效果稳定
- 模型可选MIT/Apache许可，商用安全
- 先上BM25即可用，随后加语义检索提升体验

缺点：
- 首次需要下载模型文件（可离线保存）
- 需要做简单的文本预处理（中英文分词、规范化）

适用性：
- 小到中规模FAQ（10–10k），中英文混合问法

---

### 方案 B：仅BM25关键词检索（最简）
- 只用SQLite FTS5做全文检索

优点：
- 无需模型；部署最快；资源占用最低

缺点：
- 遇到同义或改写问法时召回率下降
- 英文同义/短语变体匹配较弱

适用性：
- 数据量极小、问法固定、对召回要求不高的场景

---

### 方案 C：本地小语言模型生成式回答（LLM润色）
- 在A或B命中答案后，用本地小模型（如 Qwen 0.5B GGUF）润色输出

优点：
- 输出更自然；可做格式化或多语言风格统一

缺点：
- 增加复杂度与计算成本；需关注模型许可
- 不建议直接“生成答案”，以免偏离你提供的标准答案

适用性：
- 对文案风格有要求，但仍以“标准答案”为准绳

## 关键技术比较

| 维度 | 方案A | 方案B | 方案C（叠加） |
|---|---|---|---|
| 准确度（相似问） | 高 | 中 | 高（取决于A/B） |
| 延迟 | 低-中 | 低 | 中 |
| 资源占用 | 中 | 低 | 中-高 |
| 迭代成本 | 中 | 低 | 中-高 |
| 商用许可风险 | 低 | 低 | 低（选合规模型） |
| 离线运行 | 支持 | 支持 | 支持 |

结论：选择方案A为主线，B作为MVP起步，C为可选增强。

## 合规与版权

- 模型与库许可：
  - 首选 MIT/Apache 2.0 许可（如 multilingual-e5-small / paraphrase-multilingual-MiniLM-L12-v2）
  - 避免 CC BY-NC（非商用）和 GPL（传染性）许可模型和权重
- 第三方依赖：FastAPI、FAISS、sentence-transformers 等均为友好许可
- 数据：仅使用你自有或授权的问答内容

## 安全与可控

- 仅检索式答案：返回你提供的“标准答案”，避免模型编造
- 置信度阈值：低于阈值则拒答或请用户选择候选
- 可审计：每次回答记录来源ID与分数，便于追踪

## 性能与扩展性

- 起步数据（10条）：响应时间 < 100ms（BM25）；< 200ms（含向量）
- 扩展到1k条：仍可在CPU下稳定运行，FAISS向量内存占用可控
- 可横向扩展：将SQLite替换为PostgreSQL+pgvector（未来需要时）

## 开发与维护成本

- 开发周期：5–7天实现MVP（API就绪、无UI）
- 维护难度：低；数据导入和索引重建脚本化
- 文档与测试：提供使用手册、API说明和单元测试

## 风险清单与缓解

1. 模型下载失败或网络受限
   - 预下发模型文件；提供离线安装包
2. 多语言混合问法效果不稳
   - 采用多语言向量模型；增加别名/同义词词库
3. 误匹配导致错误回答
   - 提高阈值，默认返回候选列表；日志审计与持续调参

## 里程碑与验收标准

- 里程碑1（MVP）：BM25检索 + 导入 + /query API
- 里程碑2：向量检索融合 + 置信度阈值 + 候选输出
- 里程碑3：测试集准确率 >= 85%，基础文档完成

验收：
- 在10条FAQ数据集上，输入同义改写问题，系统能返回正确答案或合理候选；API稳定运行，日志可追踪。

---

**评估人**: AI Assistant  
**日期**: 2025-08-08  
**版本**: v1.0
